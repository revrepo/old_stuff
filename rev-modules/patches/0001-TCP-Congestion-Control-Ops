From e88346a84fd8896f48245d71133b0e1cd1dddb72 Mon Sep 17 00:00:00 2001
From: Tom Kavanagh <tom.revsw@gmail.com>
Date: Tue, 20 Jan 2015 16:57:35 -0800
Subject: [PATCH 1/3] TCP Congestion Control Ops

Adding new API vectors to the tcp congestion control ops data
structure.  These are required for the Rev Software module to
provide the required performance improvements.

Signed-off-by: Tom Kavanagh <tom.revsw@gmail.com>
---
 include/net/tcp.h     | 15 +++++++++++++++
 net/ipv4/tcp_input.c  |  8 +++++++-
 net/ipv4/tcp_output.c | 32 +++++++++++++++++++++++++-------
 3 files changed, 47 insertions(+), 8 deletions(-)

diff --git a/include/net/tcp.h b/include/net/tcp.h
index a9b7191..d512522 100644
--- a/include/net/tcp.h
+++ b/include/net/tcp.h
@@ -809,6 +809,21 @@ struct tcp_congestion_ops {
 	void (*pkts_acked)(struct sock *sk, u32 num_acked, s32 rtt_us);
 	/* get info for inet_diag (optional) */
 	void (*get_info)(struct sock *sk, u32 ext, struct sk_buff *skb);
+	/* SYN post config */
+	void (*syn_post_config)(struct sock *sk);
+	/* set new window size */
+	void (*set_nwin_size)(struct sock *sk, u32 nwin);
+	/* handle nagle test */
+	bool (*handle_nagle_test)(struct sock *sk, struct sk_buff *skb,
+				  unsigned int mss_now, int nonagle);
+	/* Session Info handler */
+	int (*get_session_info)(struct sock *sk, unsigned char *sinfo, int *len);
+	/* get congestion window quota*/
+	int (*get_cwnd_quota)(struct sock *sk, const struct sk_buff *skb);
+	/* handle send window test */
+	bool (*snd_wnd_test)(const struct tcp_sock *tp,
+			     const struct sk_buff *skb,
+			     unsigned int cur_mss);
 
 	char 		name[TCP_CA_NAME_MAX];
 	struct module 	*owner;
diff --git a/net/ipv4/tcp_input.c b/net/ipv4/tcp_input.c
index 2ab6b82..b3c393a 100644
--- a/net/ipv4/tcp_input.c
+++ b/net/ipv4/tcp_input.c
@@ -3249,6 +3249,7 @@ static inline bool tcp_may_update_window(const struct tcp_sock *tp,
 static int tcp_ack_update_window(struct sock *sk, const struct sk_buff *skb, u32 ack,
 				 u32 ack_seq)
 {
+	const struct tcp_congestion_ops *ca_ops = inet_csk(sk)->icsk_ca_ops;
 	struct tcp_sock *tp = tcp_sk(sk);
 	int flag = 0;
 	u32 nwin = ntohs(tcp_hdr(skb)->window);
@@ -3261,7 +3262,10 @@ static int tcp_ack_update_window(struct sock *sk, const struct sk_buff *skb, u32
 		tcp_update_wl(tp, ack_seq);
 
 		if (tp->snd_wnd != nwin) {
-			tp->snd_wnd = nwin;
+			if (ca_ops && ca_ops->set_nwin_size)
+				ca_ops->set_nwin_size(sk, nwin);
+			else
+				tp->snd_wnd = nwin;
 
 			/* Note, it is the only place, where
 			 * fast path is recovered for sending TCP.
@@ -5710,6 +5714,8 @@ int tcp_rcv_state_process(struct sock *sk, struct sk_buff *skb,
 
 		tcp_initialize_rcv_mss(sk);
 		tcp_fast_path_on(tp);
+		if (icsk->icsk_ca_ops && icsk->icsk_ca_ops->syn_post_config)
+			icsk->icsk_ca_ops->syn_post_config(sk);
 		break;
 
 	case TCP_FIN_WAIT1: {
diff --git a/net/ipv4/tcp_output.c b/net/ipv4/tcp_output.c
index 395f909..3080d19 100644
--- a/net/ipv4/tcp_output.c
+++ b/net/ipv4/tcp_output.c
@@ -1832,6 +1832,7 @@ static int tcp_mtu_probe(struct sock *sk)
 static bool tcp_write_xmit(struct sock *sk, unsigned int mss_now, int nonagle,
 			   int push_one, gfp_t gfp)
 {
+	const struct tcp_congestion_ops *ca_ops = inet_csk(sk)->icsk_ca_ops;
 	struct tcp_sock *tp = tcp_sk(sk);
 	struct sk_buff *skb;
 	unsigned int tso_segs, sent_pkts;
@@ -1862,7 +1863,11 @@ static bool tcp_write_xmit(struct sock *sk, unsigned int mss_now, int nonagle,
 			goto repair; /* Skip network transmission */
 		}
 
-		cwnd_quota = tcp_cwnd_test(tp, skb);
+		if (ca_ops->get_cwnd_quota)
+			cwnd_quota = ca_ops->get_cwnd_quota(sk, skb);
+		else
+			cwnd_quota = tcp_cwnd_test(tp, skb);
+
 		if (!cwnd_quota) {
 			if (push_one == 2)
 				/* Force out a loss probe pkt. */
@@ -1871,14 +1876,27 @@ static bool tcp_write_xmit(struct sock *sk, unsigned int mss_now, int nonagle,
 				break;
 		}
 
-		if (unlikely(!tcp_snd_wnd_test(tp, skb, mss_now)))
-			break;
+		if (ca_ops->snd_wnd_test) {
+			if (unlikely(!ca_ops->snd_wnd_test(tp, skb, mss_now)))
+				break;
+		} else {
+			if (unlikely(!tcp_snd_wnd_test(tp, skb, mss_now)))
+				break;
+		}
 
 		if (tso_segs == 1) {
-			if (unlikely(!tcp_nagle_test(tp, skb, mss_now,
-						     (tcp_skb_is_last(sk, skb) ?
-						      nonagle : TCP_NAGLE_PUSH))))
-				break;
+			if (ca_ops->handle_nagle_test) {
+				if (unlikely(!ca_ops->handle_nagle_test(sk,
+					     skb, mss_now,
+					     (tcp_skb_is_last(sk, skb) ?
+					      nonagle : TCP_NAGLE_PUSH))))
+					break;
+			} else {
+				if (unlikely(!tcp_nagle_test(tp, skb, mss_now,
+					     (tcp_skb_is_last(sk, skb) ?
+					      nonagle : TCP_NAGLE_PUSH))))
+					break;
+			}
 		} else {
 			if (!push_one && tcp_tso_should_defer(sk, skb))
 				break;
-- 
1.9.1

